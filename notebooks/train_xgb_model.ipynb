{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3b6df6",
   "metadata": {},
   "source": [
    "# Steam Games Success Prediction - XGBRegressor Model\n",
    "\n",
    "## 1. Import Libraries and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62102008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import joblib\n",
    "import time\n",
    "from data_preprocessing import base_pipeline, final_cleaning_pipeline, scaling_pipeline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa491e",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29231bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipeline.set_params(data_loading__filepath=\"../data/raw/games.csv\")\n",
    "\n",
    "print(\"Loading and preprocessing data...\")\n",
    "pre_outlier_df = base_pipeline.fit_transform(None)\n",
    "pre_scaling_df = final_cleaning_pipeline.fit_transform(pre_outlier_df)\n",
    "df = scaling_pipeline.fit_transform(pre_scaling_df)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Available columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a27206",
   "metadata": {},
   "source": [
    "## 3. Define Target and Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe57a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"estimated_owners_calculated\"\n",
    "y = df[target_column].copy()\n",
    "\n",
    "columns_to_ignore = [\n",
    "    target_column,\n",
    "    \"average_playtime_forever\",\n",
    "    \"median_playtime_forever\",\n",
    "]\n",
    "\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "feature_columns = [col for col in numeric_features if col not in columns_to_ignore]\n",
    "\n",
    "X = df[feature_columns].copy()\n",
    "\n",
    "print(f\"Target variable: {target_column}\")\n",
    "print(f\"Target range: {y.min():.0f} - {y.max():.0f}\")\n",
    "print(f\"Number of features: {len(feature_columns)}\")\n",
    "print(f\"Features: {feature_columns}\")\n",
    "print(\"Target variable statistics:\")\n",
    "print(f\"   Mean: {y.mean():.0f}\")\n",
    "print(f\"   Median: {y.median():.0f}\")\n",
    "print(f\"   Std: {y.std():.0f}\")\n",
    "\n",
    "fig = px.histogram(\n",
    "    x=y,\n",
    "    nbins=50,\n",
    "    title=\"Distribution of Target Variable (Estimated Owners)\",\n",
    "    labels={\"x\": \"Estimated Owners (scaled)\", \"y\": \"Frequency\"},\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "fig.update_layout(showlegend=False, width=800, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de465ef",
   "metadata": {},
   "source": [
    "## 4. Stratified Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d28877",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 5\n",
    "y_binned = pd.cut(y, bins=n_bins, labels=False)\n",
    "\n",
    "print(\"Bin distributions:\")\n",
    "bin_counts = pd.Series(y_binned).value_counts().sort_index()\n",
    "for i, count in enumerate(bin_counts):\n",
    "    print(f\"   Bin {i}: {count} samples\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y_binned\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"   Train mean: {y_train.mean():.0f}\")\n",
    "print(f\"   Test mean: {y_test.mean():.0f}\")\n",
    "print(f\"   Train std: {y_train.std():.0f}\")\n",
    "print(f\"   Test std: {y_test.std():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f69dd",
   "metadata": {},
   "source": [
    "## 5. Train XGBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257889cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training XGBoost model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=125,  # Number of trees (boosting rounds)\n",
    "    max_depth=35,  # Maximum tree depth\n",
    "    min_child_weight=14,\n",
    "    learning_rate=0.085,  # Step size shrinkage\n",
    "    subsample=0.9,  # Subsample ratio of the training instances\n",
    "    colsample_bytree=0.9,  # Subsample ratio of columns when constructing each tree\n",
    "    objective=\"reg:squarederror\",  # Regression objective\n",
    "    random_state=42,  # For reproducibility\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "print(f\"Number of trees: {xgb_model.n_estimators}\")\n",
    "print(f\"Max depth: {xgb_model.max_depth}\")\n",
    "print(f\"Learning rate: {xgb_model.learning_rate}\")\n",
    "print(f\"Subsample: {xgb_model.subsample}\")\n",
    "print(f\"Colsample bytree: {xgb_model.colsample_bytree}\")\n",
    "print(f\"Min child weight: {xgb_model.min_child_weight}\")\n",
    "print(f\"Number of features used: {xgb_model.n_features_in_}\")\n",
    "\n",
    "models_dir = \"../models/xgb_regressor\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "model_filename = \"model.joblib\"\n",
    "model_path = os.path.join(models_dir, model_filename)\n",
    "\n",
    "joblib.dump(xgb_model, model_path)\n",
    "print(f\"\\nModel saved to: {model_path}\")\n",
    "\n",
    "feature_columns_path = os.path.join(models_dir, \"feature_columns.joblib\")\n",
    "joblib.dump(feature_columns, feature_columns_path)\n",
    "print(f\"Feature columns saved to: {feature_columns_path}\")\n",
    "\n",
    "scaling_pipeline_path = os.path.join(models_dir, \"scaling_pipeline.joblib\")\n",
    "joblib.dump(scaling_pipeline, scaling_pipeline_path)\n",
    "print(f\"Scaling pipeline saved to: {scaling_pipeline_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f2ad7",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb742e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"R² Score:\")\n",
    "print(f\"   Training: {train_r2:.3f}\")\n",
    "print(f\"   Test: {test_r2:.3f}\")\n",
    "print(f\"\\nMean Absolute Error:\")\n",
    "print(f\"   Training: {train_mae:.0f}\")\n",
    "print(f\"   Test: {test_mae:.0f}\")\n",
    "print(f\"\\nRoot Mean Square Error:\")\n",
    "print(f\"   Training: {train_rmse:.0f}\")\n",
    "print(f\"   Test: {test_rmse:.0f}\")\n",
    "print(f\"\\nOverfitting measure (Train R² - Test R²): {train_r2 - test_r2:.3f}\")\n",
    "\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\"feature\": feature_columns, \"importance\": xgb_model.feature_importances_}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "print(\"=\" * 40)\n",
    "for i, (feature, importance) in enumerate(feature_importance.head(10).values):\n",
    "    print(f\"{i + 1:2d}. {feature:<25} {importance:.3f}\")\n",
    "\n",
    "fig_importance = px.bar(\n",
    "    feature_importance.head(10),\n",
    "    x=\"importance\",\n",
    "    y=\"feature\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Top 10 Feature Importances - XGBoost\",\n",
    "    labels={\"importance\": \"Importance\", \"feature\": \"Features\"},\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "fig_importance.update_layout(height=500, yaxis={\"categoryorder\": \"total ascending\"})\n",
    "fig_importance.show()\n",
    "\n",
    "pred_actual_df = pd.DataFrame({\"actual\": y_test, \"predicted\": y_test_pred})\n",
    "\n",
    "fig_pred_actual = px.scatter(\n",
    "    pred_actual_df,\n",
    "    x=\"actual\",\n",
    "    y=\"predicted\",\n",
    "    title=f\"Predicted vs Actual (Test Set) - R² = {test_r2:.3f}\",\n",
    "    labels={\"actual\": \"Actual Values\", \"predicted\": \"Predicted Values\"},\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "min_val = min(y_test.min(), y_test_pred.min())\n",
    "max_val = max(y_test.max(), y_test_pred.max())\n",
    "fig_pred_actual.add_scatter(\n",
    "    x=[min_val, max_val],\n",
    "    y=[min_val, max_val],\n",
    "    mode=\"lines\",\n",
    "    name=\"Perfect Prediction\",\n",
    "    line=dict(color=\"red\", dash=\"dash\"),\n",
    ")\n",
    "fig_pred_actual.update_layout(height=500, width=600)\n",
    "fig_pred_actual.show()\n",
    "\n",
    "residuals = y_test - y_test_pred\n",
    "residuals_df = pd.DataFrame({\"predicted\": y_test_pred, \"residuals\": residuals})\n",
    "\n",
    "fig_residuals = px.scatter(\n",
    "    residuals_df,\n",
    "    x=\"predicted\",\n",
    "    y=\"residuals\",\n",
    "    title=\"Residual Plot - XGBoost\",\n",
    "    labels={\"predicted\": \"Predicted Values\", \"residuals\": \"Residuals\"},\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "fig_residuals.add_hline(y=0, line_dash=\"dash\", line_color=\"red\")\n",
    "fig_residuals.update_layout(height=500, width=600)\n",
    "fig_residuals.show()\n",
    "\n",
    "fig_dist = px.histogram(\n",
    "    x=[y_test_pred, y_test],\n",
    "    nbins=30,\n",
    "    title=\"Distribution Comparison: Predicted vs Actual - XGBoost\",\n",
    "    labels={\"x\": \"Values\", \"y\": \"Frequency\"},\n",
    "    template=\"plotly_white\",\n",
    "    barmode=\"overlay\",\n",
    "    opacity=0.7,\n",
    ")\n",
    "fig_dist.data[0].name = \"Predicted\"\n",
    "fig_dist.data[1].name = \"Actual\"\n",
    "fig_dist.update_layout(height=500, width=600)\n",
    "fig_dist.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
